{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3135ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,num_convs):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_convs):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels if i == 0 else out_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size = 3,\n",
    "                    padding = 1\n",
    "                )\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.BatchNorm2d(num_features = out_channels)\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.ReLU(inplace = True)\n",
    "            )\n",
    "        layers.append(\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size = 2, stride = 2\n",
    "            )\n",
    "        ) # shape reduces to half\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc9138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet_CIFAR(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            VGGBlock(in_channels = 3, out_channels = 64, num_convs =2), # Block 1 with 2 convs & 1 maxpool  Shape (64, 16, 16)\n",
    "            VGGBlock(in_channels=64 , out_channels=128 , num_convs = 3), # Block2  with 3 convs & 1 maxpool  Shape (128, 8, 8)\n",
    "            VGGBlock(in_channels=128 , out_channels=256 , num_convs = 3), # Block3  with 3 convs & 1 maxpool Shape (256, 4, 4)\n",
    "            VGGBlock(in_channels=256 , out_channels=512 , num_convs = 3), # Block4  with 3 convs & 1 maxpool Shape (512, 2, 2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 2 * 2,4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "536b4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CIFAR(architecture_class,optimizer_name = 'Adam',epochs = 10):\n",
    "    # Data loading and transformation\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.4914, 0.4822, 0.4465),\n",
    "            std=(0.2470, 0.2435, 0.2616)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.4914, 0.4822, 0.4465),\n",
    "            std=(0.2470, 0.2435, 0.2616)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=\"./data-CIFAR\",download = True, train=True, transform=transform_train)\n",
    "    test_dataset  = datasets.CIFAR10(root=\"./data-CIFAR\",download = True, train=False, transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Optimizer Part\n",
    "\n",
    "    model = architecture_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    else:\n",
    "        print(\"Unknown optimizer! Defaulting to Adam.\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # ------- training loop --------\n",
    "\n",
    "    epochs = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "            f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "            f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "    \n",
    "    # Test Evaluation Part\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100*correct/total:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f3d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Loss: 2.1165 Train Acc: 17.38%\n",
      "Epoch [2/30] Loss: 1.8515 Train Acc: 24.83%\n",
      "Epoch [3/30] Loss: 1.6581 Train Acc: 33.84%\n",
      "Epoch [4/30] Loss: 1.5088 Train Acc: 41.72%\n",
      "Epoch [5/30] Loss: 1.3403 Train Acc: 49.91%\n",
      "Epoch [6/30] Loss: 1.1162 Train Acc: 61.05%\n",
      "Epoch [7/30] Loss: 0.9366 Train Acc: 67.61%\n",
      "Epoch [8/30] Loss: 0.8313 Train Acc: 71.60%\n",
      "Epoch [9/30] Loss: 0.7426 Train Acc: 75.11%\n",
      "Epoch [10/30] Loss: 0.6684 Train Acc: 77.94%\n",
      "Epoch [11/30] Loss: 0.6052 Train Acc: 80.02%\n",
      "Epoch [12/30] Loss: 0.5733 Train Acc: 81.16%\n",
      "Epoch [13/30] Loss: 0.5282 Train Acc: 82.76%\n",
      "Epoch [14/30] Loss: 0.4961 Train Acc: 83.91%\n",
      "Epoch [15/30] Loss: 0.4613 Train Acc: 85.02%\n",
      "Epoch [16/30] Loss: 0.4379 Train Acc: 85.75%\n",
      "Epoch [17/30] Loss: 0.4155 Train Acc: 86.38%\n",
      "Epoch [18/30] Loss: 0.3905 Train Acc: 87.27%\n",
      "Epoch [19/30] Loss: 0.3709 Train Acc: 87.88%\n",
      "Epoch [20/30] Loss: 0.3529 Train Acc: 88.61%\n",
      "Epoch [21/30] Loss: 0.3287 Train Acc: 89.39%\n",
      "Epoch [22/30] Loss: 0.3205 Train Acc: 89.60%\n",
      "Epoch [23/30] Loss: 0.3024 Train Acc: 90.01%\n",
      "Epoch [24/30] Loss: 0.2940 Train Acc: 90.52%\n",
      "Epoch [25/30] Loss: 0.2774 Train Acc: 91.07%\n",
      "Epoch [26/30] Loss: 0.2678 Train Acc: 91.24%\n",
      "Epoch [27/30] Loss: 0.2555 Train Acc: 91.62%\n",
      "Epoch [28/30] Loss: 0.2413 Train Acc: 92.17%\n",
      "Epoch [29/30] Loss: 0.2347 Train Acc: 92.36%\n",
      "Epoch [30/30] Loss: 0.2205 Train Acc: 92.74%\n",
      "Test Accuracy: 88.64%\n"
     ]
    }
   ],
   "source": [
    "train_CIFAR(architecture_class=VGGNet_CIFAR,optimizer_name='Adam',epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0b991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
